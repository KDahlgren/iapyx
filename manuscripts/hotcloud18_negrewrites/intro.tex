\section{Introduction} \label{intro}
One of the most universal experiences partaken by the subset of people in the world captivated by the wonders of computer programing is software debugging. Lore preceding even Grace Hopper's discovery of the impudent moth dead in the relays of the Mark II \cite{Kidwell:1998:SEC:612504.612741} is rife with testaments of the chore that is error handling and remediation. While the modern decade enjoys a number of tools, conventions, and practices supporting a level of relatively easy and instant gratification when informing developers of data relevant to software issues, the degree of sophistication does not yet extend toward distributed computing. State-of-the-art debugging techniques for distributed applications range from traditional regression and integration testing and model checking to more sophisticated distributed tracing infrastructures and fault injection experimentation frameworks \cite{36356, 203322, Zave:2012:ULM:2185376.2185383, Chang:2015:CMI:2785956.2790038, Beschastnikh:2016:DDS:2975594.2909480}. However, all existing techniques possess significant limitations with respect to ultimate usefulness and scalability, especially as a result of a typically heavy reliance upon domain-specific knowledge to manage debugging information complexity and overall tractability. Fundamentally, debugging distributed software is hard, even after decades of dedicated research, and the world needs better tools embracing the unique confounding characteristics of the paradigm. 

A core feature of software debugging is engaging in the mental exercise of asking why and why-not questions while studying the history of behaviors performed during an execution. To illustrate, suppose process $A$ runs after process $B$ if condition $C_1$ is true and condition $C_2$ is NOT true. If process $A$ doesn?t run, then the developer investigates why $B$ didn?t run, since $A$ possess a direct dependency relationship with $B$. Additionally, because $B$ depends upon a branching condition, the developer, consciously or subconsciously, applies De Morgan's Law \cite{Epp:2010:DMA:1941983} on the condition dependencies to determine that $B$ could only NOT run as a result of three possible scenarios: condition $C_1$ failed OR condition $C_2$ succeeded OR condition $C_1$ failed AND condition $C_2$ succeeded. Furthermore, suppose $C_2$ succeeded. Then, the developer faces a theoretically infinite set of scenarios which could have cause $C_2$ to not be false. The process of analyzing dependencies and backtracking over branching behaviors using De Morgan?s Law continues until the developer successfully characterizes the nature of the bug and gathers an adequate understanding of the algorithm and workflow details to design an appropriate solution.

While numerous techniques, primarily derived from the Data Provenance literature, exist for characterizing `positive? provenance, i.e. why events occurred, comparatively few techniques provide generalizable and satisfactory methods for describing `negative? provenance, i.e. why events do not occur.  A primary obstacle tied to the latter arena is, fundamentally, that the number of possible causes for why something didn?t happen is theoretically infinite, with colloquial discussion condensing the circumstance to the Butterfly Effect \cite{10.1007/978-3-319-12688-3_6}.

Fortunately, software developers tend to be very practical people and ignore the theoretical infinity on a daily basis by realizing, within the context of a particular set of applications, only a small set of behaviors are truly relevant in the task describing why events do and do not occur during an execution. Specifically, bug solutions often derive from constraints on data relevant to program implementations, targeted sets of inputs, and, in the realm of distributed computing, complications introduce via assumptions regarding data distribution and inter-process or inter-node communications. As demonstrated in the example above, De Morgan?s Law represents a tool essential for that reasoning process. However, existing tools used in the support of debugging distributed software relying upon execution analyses fail to harness De Morgan?s Law and instead choose to utilize less intuitive reasoning strategies, which ultimately result in more complex debugging information.

Negative Rewrites encapsulates a new method of characterizing why-not provenance. The technique embodies an automatic system execution analysis method harnessing the application of De Morgan's Law to approximate the debugging process as closely as possible to the above intuitive example. The resulting technique augments existing provenance collection methods to offer smaller and more intuitive explanations for why events do not occur during distributed executions. In essence, using De Morgan's Law allows the conversion of applications which rely upon absent events into equivalent applications relying only upon positive formulations of the absent events. As a result, any system execution analysis platform incorporating Negative Rewrites can consume and analyze the results using existing positive provenance infrastructure to generate explanations for both event successes and event failures. 

After establishing a running example to ease technique illustration, the Section \ref{neg_rewrites} details the process of analyzing system executions using Negative Rewrites. Subsequently, Section \ref{eval} examines the impact of applying Negative Rewrites within an existing distributed protocol analysis tool. Finally, Section \ref{rw} contextualizes the technique with comparisons to existing work and Section \ref{fw} overviews areas of future work afforded by Negative Rewrites. 

\section{Running Example}
Negative Rewrites is arguably best introduced with an accompanying small example capable of illustrating the different steps of the technique and evolve with different aspects of the discussion. Consider the distributed protocol stated declaratively in the following Datalog snippet:
\begin{align}
co&nnections( Node2, Node1, Time2 ) \leftarrow \\
	&syn( Node1, Node2, Time0 ), \\
	&syn\_ack( Node2, Node1, Time1 ), \\
	&ack( Node1, Node2, Time2 ), \\
	&\neg \;\; i\_think\_its\_crashed( Node1, Node2, Time2 ), \\
	&Time0<Time1, \\
	&Time1<Time2
\label{tcp}
\end{align}

The statement encodes the high-level logic for the TCP-Handshake \cite{RFC0793}. The protocol establishes a connection between nodes $Node1$ and $Node2$ if (1) $Node1$ sends a SYN request to $Node2$ at some time, (2) $Node2$ sends a SYN$\_$ACK message to $Node1$ at a subsequent time, (3) $Node1$ sends an ACK message to $Node2$ at some subsequent time, and (4) $Node1$ is not under the impression that $Node2$ is dead at the time it receives the $ACK$. The exact methods for determining SYN, SYN$\_$ACK, ACK, and node deaths over the course of an execution are naturally open to definition methods of coarser and finer granularity. However, the abstract definition of the connection protocol is sufficient to illustrate the mechanisms of the Negative Rewrites technique.